{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this iPython notebook, we integrate data for running SVM/logistic regression from start to finish. The code depends on quicksect.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import glob\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Import data</h3>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Place data in their respective folders.  \n",
    "- CHROMATIN - contains chromatin marks files, excluding chromM and chromX\n",
    "- p300 - contains the distal p300 txt file\n",
    "- eRNA - contains the condensed eRNA txt file that only has data for the 4 cell types we looked at\n",
    "- TFBS - contains the sequence data gz file which is used for all cells"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Set cell name\n",
    "CELLNAME = \"HepG2\"\n",
    "CELLNAME_2 = \"CNhs12328\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#function for importing chromatin marks, to be used under matching intervals\n",
    "def get_data(filename, chrom):\n",
    "    dat = pd.read_table(filename, compression = 'gzip', skiprows=1)\n",
    "    nrows = dat.shape[0]\n",
    "    dat['chr'] = chrom\n",
    "    dat['lower'] = np.arange(1,200*(nrows),200)\n",
    "    dat['upper'] = np.arange(200,200*(nrows+1),200).reshape(nrows,1)\n",
    "    #dat.head()\n",
    "    return dat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div style=\"max-height:1000px;max-width:1500px;overflow:auto;\">\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>chr</th>\n",
       "      <th>lower</th>\n",
       "      <th>upper</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td> chr10</td>\n",
       "      <td> 100009001</td>\n",
       "      <td> 100009201</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td> chr10</td>\n",
       "      <td> 100022401</td>\n",
       "      <td> 100022601</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     chr      lower      upper\n",
       "0  chr10  100009001  100009201\n",
       "1  chr10  100022401  100022601"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "file_name = glob.glob('data/p300/*.txt')[0] # get filename\n",
    "p300 = pd.read_table(file_name, header=None)\n",
    "p300.columns = ['chr','lower']\n",
    "p300['upper'] = p300['lower']+200\n",
    "p300.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div style=\"max-height:1000px;max-width:1500px;overflow:auto;\">\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>chr</th>\n",
       "      <th>lower</th>\n",
       "      <th>upper</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td> 1</td>\n",
       "      <td> 918449</td>\n",
       "      <td> 918555</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td> 1</td>\n",
       "      <td> 936652</td>\n",
       "      <td> 937138</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  chr   lower   upper\n",
       "7   1  918449  918555\n",
       "8   1  936652  937138"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_table('data/eRNA/eRNA_condensed.txt')\n",
    "eRNA = df[df[CELLNAME_2]>0] # select rows with TPM>0\n",
    "eRNA = eRNA.iloc[:,0:3]\n",
    "eRNA.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div style=\"max-height:1000px;max-width:1500px;overflow:auto;\">\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>chr</th>\n",
       "      <th>lower</th>\n",
       "      <th>upper</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td> chr1</td>\n",
       "      <td> 894640</td>\n",
       "      <td> 894654</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td> chr1</td>\n",
       "      <td> 894641</td>\n",
       "      <td> 894657</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    chr   lower   upper\n",
       "0  chr1  894640  894654\n",
       "1  chr1  894641  894657"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tfbs = pd.read_table('data/TFBS/tfbsConsSites.txt.gz', compression = 'gzip', header=None)\n",
    "tfbs = tfbs.ix[:, 1:3]\n",
    "tfbs.columns = ['chr','lower','upper']\n",
    "tfbs.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Match overlapping intervals</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Integrating data for Chromosome 10\n",
      "Added p300\n",
      "Added eRNA\n",
      "Added tfbs\n",
      "Integrating data for Chromosome 11\n",
      "Added p300\n",
      "Added eRNA\n",
      "Added tfbs\n",
      "Integrating data for Chromosome 12\n",
      "Added p300\n",
      "Added eRNA\n",
      "Added tfbs\n",
      "Integrating data for Chromosome 13\n",
      "Added p300\n",
      "Added eRNA\n",
      "Added tfbs\n",
      "Integrating data for Chromosome 14\n",
      "Added p300\n",
      "Added eRNA\n",
      "Added tfbs\n",
      "Integrating data for Chromosome 15\n",
      "Added p300\n",
      "Added eRNA\n",
      "Added tfbs\n",
      "Integrating data for Chromosome 16\n",
      "Added p300\n",
      "Added eRNA\n",
      "Added tfbs\n",
      "Integrating data for Chromosome 17\n",
      "Added p300\n",
      "Added eRNA\n",
      "Added tfbs\n",
      "Integrating data for Chromosome 18\n",
      "Added p300\n",
      "Added eRNA\n",
      "Added tfbs\n",
      "Integrating data for Chromosome 19\n",
      "Added p300\n",
      "Added eRNA\n",
      "Added tfbs\n",
      "Integrating data for Chromosome 1\n",
      "Added p300\n",
      "Added eRNA\n",
      "Added tfbs\n",
      "Integrating data for Chromosome 20\n",
      "Added p300\n",
      "Added eRNA\n",
      "Added tfbs\n",
      "Integrating data for Chromosome 21\n",
      "Added p300\n",
      "Added eRNA\n",
      "Added tfbs\n",
      "Integrating data for Chromosome 22\n",
      "Added p300\n",
      "Added eRNA\n",
      "Added tfbs\n",
      "Integrating data for Chromosome 2\n",
      "Added p300\n",
      "Added eRNA\n",
      "Added tfbs\n",
      "Integrating data for Chromosome 3\n",
      "Added p300\n",
      "Added eRNA\n",
      "Added tfbs\n",
      "Integrating data for Chromosome 4\n",
      "Added p300\n",
      "Added eRNA\n",
      "Added tfbs\n",
      "Integrating data for Chromosome 5\n",
      "Added p300\n",
      "Added eRNA\n",
      "Added tfbs"
     ]
    }
   ],
   "source": [
    "files = glob.glob('data/CHROMATIN/*.txt.gz') # create the list of chromatin marks file names\n",
    "data_chroms = []\n",
    "for filename in files:\n",
    "    chrom = os.path.split(filename)[1].split(\"_\")[1][3:] # get chromosome number from file name\n",
    "    print \"Integrating data for Chromosome \" + chrom\n",
    "    data_histones = get_data(filename, chrom)     # Import chromatin marks\n",
    "    # Select only rows of data with corresponding chromosome number\n",
    "    data_list = []\n",
    "    data_list.append(p300[p300['chr']=='chr'+chrom])\n",
    "    data_list.append(eRNA[eRNA['chr']==chrom])\n",
    "    data_list.append(tfbs[tfbs['chr']=='chr'+chrom])\n",
    "    data_names = ['p300','eRNA','tfbs']\n",
    "    \n",
    "    # Find overlapping intervals\n",
    "    query = zip(data_histones['lower'],data_histones['upper'])\n",
    "    \n",
    "    for d, name in zip(data_list, data_names):\n",
    "        data = zip(d['lower'],d['upper'])\n",
    "\n",
    "        # Modified code from: https://www.biostars.org/p/99/\n",
    "        from random import randint, seed\n",
    "        from quicksect import IntervalNode\n",
    "        def find(start, end, tree):\n",
    "            #Finds a list with the overlapping intervals\n",
    "            out = []\n",
    "            tree.intersect( start, end, lambda x: out.append(x) )\n",
    "            return int(not not out) #return 1 if there is an intersection\n",
    "\n",
    "        # start the root at the first element\n",
    "        start, end = data[0]\n",
    "        tree = IntervalNode( start, end )\n",
    "\n",
    "        # build an interval tree from the rest of the data\n",
    "        for start, end in data[1:]:\n",
    "            tree = tree.insert( start, end )\n",
    "\n",
    "        overlap = []\n",
    "        for start, end in query:\n",
    "            overlap.append(find(start, end , tree))\n",
    "\n",
    "        data_histones[name] = overlap\n",
    "        print \"Added \" + name\n",
    "        #print data_histones[name].value_counts()\n",
    "    data_chroms.append(data_histones)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "features = pd.concat(data_chroms)\n",
    "features = features.ix[:, [8,9,10,0,1,2,3,4,5,6,7,11,12,13]] #rearrange columns\n",
    "features.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Write to output file</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "new_filename = \"data/\"+ CELLNAME + \"_features.txt\"\n",
    "with open(new_filename, 'w') as the_file:\n",
    "    features.to_csv(the_file, sep='\\t', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
